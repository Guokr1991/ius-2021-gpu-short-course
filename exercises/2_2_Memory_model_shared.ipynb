{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a103c6-a66a-4139-bcbf-d1ffe578a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import numpy as np\n",
    "# from numba import cuda, float32\n",
    "\n",
    "# thread_block_size_deafult = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1484ce-8eca-4599-8b03-37aaf37e9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @cuda.jit\n",
    "# def convolve_kernel(y, x, h):\n",
    "#     i = cuda.blockIdx.x*cuda.blockDim.x + cuda.threadIdx.x\n",
    "    \n",
    "#     if i >= y.shape[0]:\n",
    "#         return\n",
    "    \n",
    "#     filter_size = len(h)\n",
    "#     x_sm = cuda.shared.array(shape=0, dtype=float32)\n",
    "#     sm_size = cuda.blockDim.x+filter_size-1\n",
    "    \n",
    "#     # Copy a portion global memory data to shared memory.\n",
    "#     k = i - (filter_size-1) # The current position in the global memory.\n",
    "#     k_sm = cuda.threadIdx.x # The current position in the shared memory.  \n",
    "#     while k_sm < sm_size:\n",
    "#         if k < 0:\n",
    "#             x_sm[k_sm] = 0.0\n",
    "#         else:\n",
    "#             x_sm[k_sm] = x[k]\n",
    "#         k_sm += cuda.blockDim.x\n",
    "#         k    += cuda.blockDim.x\n",
    "\n",
    "#     cuda.syncthreads()\n",
    "    \n",
    "#     k_sm = cuda.threadIdx.x+filter_size-1\n",
    "#     value = 0.0\n",
    "#     for j in range(filter_size):\n",
    "#         value += x_sm[k_sm-j]*h[j]\n",
    "#     y[i] = value\n",
    "\n",
    "    \n",
    "# def convolve(y, x, h):\n",
    "#     thread_block_size = min(thread_block_size_deafult, len(y))\n",
    "#     block_size = (thread_block_size, )\n",
    "#     grid_size = (math.ceil(len(y)/block_size[0]), )\n",
    "#     filter_size = len(h)\n",
    "#     shared_memory_size = thread_block_size+filter_size-1\n",
    "#     shared_memory_size_bytes = shared_memory_size * y.dtype.itemsize\n",
    "#     convolve_kernel[grid_size, block_size, 0, shared_memory_size_bytes](y, x, h)  \n",
    "    \n",
    "    \n",
    "# x = np.array([0, 1, 2, 3, 4])\n",
    "# h = np.array([0, 1, 2])\n",
    "# y_gpu = cuda.device_array(len(x))\n",
    "\n",
    "# convolve(y_gpu, x, h)\n",
    "\n",
    "# y_host = y_gpu.copy_to_host()\n",
    "# np.testing.assert_equal(y_host, [0, 0, 1, 4, 7])\n",
    "# y_host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cfdf9cb-b95b-4fea-9081-eb41709d964a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 2.2-convolve-1d-shared-memory.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 2.2-convolve-1d-shared-memory.py\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda, float32\n",
    "\n",
    "thread_block_size_deafult = 256\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def convolve_kernel(y, x, h):\n",
    "    i = cuda.blockIdx.x*cuda.blockDim.x + cuda.threadIdx.x\n",
    "    \n",
    "    if i >= y.shape[0]:\n",
    "        return\n",
    "    \n",
    "    filter_size = len(h)\n",
    "    x_sm = cuda.shared.array(shape=0, dtype=float32)\n",
    "    sm_size = cuda.blockDim.x+filter_size-1\n",
    "    \n",
    "    # Copy a portion global memory data to shared memory.\n",
    "    k = i - (filter_size-1) # The current position in the global memory.\n",
    "    k_sm = cuda.threadIdx.x # The current position in the shared memory.  \n",
    "    while k_sm < sm_size:\n",
    "        if k < 0:\n",
    "            x_sm[k_sm] = float32(0.0)\n",
    "        else:\n",
    "            x_sm[k_sm] = x[k]\n",
    "        k_sm += cuda.blockDim.x\n",
    "        k    += cuda.blockDim.x\n",
    "\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    k_sm = cuda.threadIdx.x+filter_size-1\n",
    "    value = float32(0.0)\n",
    "    for j in range(filter_size):\n",
    "        value += x_sm[k_sm-j]*h[j]\n",
    "    y[i] = value\n",
    "\n",
    "    \n",
    "def convolve(y, x, h):\n",
    "    thread_block_size = min(thread_block_size_deafult, len(y))\n",
    "    block_size = (thread_block_size, )\n",
    "    grid_size = (math.ceil(len(y)/block_size[0]), )\n",
    "    filter_size = len(h)\n",
    "    shared_memory_size = thread_block_size+filter_size-1\n",
    "    shared_memory_size_bytes = shared_memory_size*y.dtype.itemsize\n",
    "    convolve_kernel[grid_size, block_size, cuda.default_stream(), shared_memory_size_bytes](y, x, h)  \n",
    "    \n",
    "# Test data.\n",
    "n = 1024*64*16*16\n",
    "\n",
    "for i in range(20):\n",
    "    x_host = np.random.rand(n).astype(np.float32)\n",
    "    h_host = np.random.rand(256).astype(np.float32)\n",
    "    y_gpu = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "    x_gpu = cuda.to_device(x_host)\n",
    "    h_gpu = cuda.to_device(h_host)\n",
    "    convolve(y_gpu, x_gpu, h_gpu)\n",
    "    y_host = y_gpu.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4693f39-0d9f-4f5a-9dca-0c65c74bc013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==39273== NVPROF is profiling process 39273, command: python 2.2-convolve-1d-shared-memory.py\n",
      "==39273== Profiling application: python 2.2-convolve-1d-shared-memory.py\n",
      "==39273== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   82.35%  4.33889s        20  216.94ms  215.59ms  220.54ms  cudapy::__main__::convolve_kernel$241(Array<float, int=1, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\n",
      "                    9.30%  490.15ms        40  12.254ms     928ns  24.752ms  [CUDA memcpy HtoD]\n",
      "                    8.34%  439.63ms        20  21.981ms  21.596ms  22.360ms  [CUDA memcpy DtoH]\n",
      "      API calls:   86.91%  4.78460s        20  239.23ms  237.76ms  243.08ms  cuMemcpyDtoH\n",
      "                    8.79%  483.79ms        40  12.095ms  11.866us  24.378ms  cuMemcpyHtoD\n",
      "                    2.27%  125.20ms         1  125.20ms  125.20ms  125.20ms  cuDevicePrimaryCtxRetain\n",
      "                    1.02%  56.156ms        52  1.0799ms  3.4500us  1.8431ms  cuMemFree\n",
      "                    0.76%  41.948ms         1  41.948ms  41.948ms  41.948ms  cuLinkAddData\n",
      "                    0.22%  12.158ms        60  202.63us  8.9100us  1.6687ms  cuMemAlloc\n",
      "                    0.01%  421.27us        20  21.063us  17.897us  22.759us  cuLaunchKernel\n",
      "                    0.00%  162.63us         1  162.63us  162.63us  162.63us  cuModuleLoadDataEx\n",
      "                    0.00%  128.00us       101  1.2670us     120ns  53.468us  cuDeviceGetAttribute\n",
      "                    0.00%  97.839us       143     684ns     233ns  2.8610us  cuCtxGetCurrent\n",
      "                    0.00%  94.302us         1  94.302us  94.302us  94.302us  cuLinkComplete\n",
      "                    0.00%  66.917us         2  33.458us  31.119us  35.798us  cuDeviceGetName\n",
      "                    0.00%  51.130us         1  51.130us  51.130us  51.130us  cuDeviceTotalMem\n",
      "                    0.00%  49.817us       141     353ns     183ns     782ns  cuCtxGetDevice\n",
      "                    0.00%  45.394us         1  45.394us  45.394us  45.394us  cuLinkCreate\n",
      "                    0.00%  20.488us         1  20.488us  20.488us  20.488us  cuMemGetInfo\n",
      "                    0.00%  10.206us         1  10.206us  10.206us  10.206us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9270us         4     481ns     236ns     884ns  cuDeviceGetCount\n",
      "                    0.00%  1.6420us         1  1.6420us  1.6420us  1.6420us  cuInit\n",
      "                    0.00%  1.5380us         5     307ns     166ns     610ns  cuFuncGetAttribute\n",
      "                    0.00%  1.4730us         3     491ns     307ns     654ns  cuDeviceGet\n",
      "                    0.00%  1.2380us         1  1.2380us  1.2380us  1.2380us  cuLinkDestroy\n",
      "                    0.00%  1.0910us         1  1.0910us  1.0910us  1.0910us  cuModuleGetFunction\n",
      "                    0.00%     905ns         1     905ns     905ns     905ns  cuCtxPushCurrent\n",
      "                    0.00%     775ns         1     775ns     775ns     775ns  cuDriverGetVersion\n",
      "                    0.00%     576ns         1     576ns     576ns     576ns  cuDeviceComputeCapability\n",
      "                    0.00%     444ns         1     444ns     444ns     444ns  cudaRuntimeGetVersion\n",
      "                    0.00%     265ns         1     265ns     265ns     265ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "! nvprof python 2.2-convolve-1d-shared-memory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab55545c-373b-429b-ae34-6db83f734f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 39309 (/home/pjarosik/bin/miniconda3/envs/ius2021sc/bin/python3.8)\n",
      "==ERROR== Error: ERR_NVGPUCTRPERM - The user does not have permission to access NVIDIA GPU Performance Counters on the target device 0. For instructions on enabling permissions and to get more information see https://developer.nvidia.com/ERR_NVGPUCTRPERM\n",
      "==PROF== Disconnected from process 39309\n",
      "==ERROR== An error occurred while trying to profile.\n",
      "==WARNING== No kernels were profiled.\n",
      "==WARNING== Profiling kernels launched by child processes requires the --target-processes all option.\n"
     ]
    }
   ],
   "source": [
    "! ncu --section MemoryWorkloadAnalysis python 2.2-convolve-1d-shared-memory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02083ab4-896d-4747-9ec3-61585cebfeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 39352 (/home/pjarosik/bin/miniconda3/envs/ius2021sc/bin/python3.8)\n",
      "==ERROR== Error: ERR_NVGPUCTRPERM - The user does not have permission to access NVIDIA GPU Performance Counters on the target device 0. For instructions on enabling permissions and to get more information see https://developer.nvidia.com/ERR_NVGPUCTRPERM\n"
     ]
    }
   ],
   "source": [
    "# ! nsys profile --stats=true -t cuda python 2.2-convolve-1d-shared-memory.py\n",
    "! ncu python 2.2-convolve-1d-shared-memory.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
