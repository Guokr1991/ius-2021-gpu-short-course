{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indoor-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda, float32, int32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-nightlife",
   "metadata": {},
   "source": [
    "***\n",
    "# FIR filter\n",
    "***\n",
    "<font size=\"4\">\n",
    "The finite impulse response (FIR) filter is given by equation \\eqref{fir}\n",
    "\n",
    "\\begin{equation}\n",
    "    y_i = \\sum_{j=0}^{N-1} h_j x_{i+\\left\\lceil \\frac{N}{2} \\right\\rceil+1-j} \n",
    "    \\label{fir} \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "where *x* is an input signal, *h* is the impulse response of the filter and *y* is an output signal.\n",
    "Filtration is realised by convolving the signal with impulse response of the filter.\n",
    "\n",
    "$x_i$ is equal 0 for $i < 0$\n",
    "    \n",
    "***    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-brain",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "developing-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  7, 10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.convolve([0, 1, 2, 3, 4], [0, 1, 2], mode='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-winning",
   "metadata": {},
   "source": [
    "Examples:\n",
    "    \n",
    "```\n",
    "\n",
    "x = [0, 1, 2, 3, 4]\n",
    "h = [0, 1, 2]\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    " x = [0, 1, 2, 3, 4]      y = \n",
    "     [1, 0]               [0 ]\n",
    "     [2, 1, 0]            [1 ]\n",
    "        [2, 1, 0]         [4 ]\n",
    "           [2, 1, 0]      [7 ]\n",
    "              [2, 1]      [10]\n",
    "```\n",
    "\n",
    "```\n",
    "y[0] = h[0]*x[1]+h[1]*x[0]           = 0\n",
    "y[1] = h[0]*x[2]+h[1]*x[1]*h[2]*x[0] = 1\n",
    "y[2] = h[0]*x[3]+h[1]*x[2]*h[2]*x[1] = 4\n",
    "y[3] = h[0]*x[4]+h[1]*x[3]+h[2]*x[2] = 7\n",
    "y[4] = h[1]*x[4]+h[2]*x[3] =           10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-homework",
   "metadata": {},
   "source": [
    "### CPU implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "temporal-mexican",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  7, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convolve_cpu(x, h):\n",
    "    x = np.asarray(x)\n",
    "    h = np.asarray(h)\n",
    "    M = len(x)\n",
    "    N = len(h)\n",
    "    y = np.zeros(M, dtype=x.dtype)\n",
    "    offset = math.ceil(N/2)-1\n",
    "        \n",
    "    for i in range(M):\n",
    "        # This loop can be parallelized.\n",
    "        value = 0.0\n",
    "        for j in range(N):\n",
    "            k = i + offset - j    \n",
    "            if k >= 0 and k < M:\n",
    "                value += x[k]*h[j]\n",
    "        y[i] = value\n",
    "        \n",
    "    return y\n",
    "\n",
    "\n",
    "convolve_cpu([0, 1, 2, 3, 4], [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brave-conducting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed.\n",
      "Benchmark result: \n",
      "Average processing time: 1.2039 seconds (+/- 0.0141), median: 1.2039\n"
     ]
    }
   ],
   "source": [
    "def test_convolve(func):\n",
    "    # Test simple case\n",
    "    x = np.array([0, 1, 2, 3, 4], dtype=np.float32)\n",
    "    h = np.array([0, 1, 2], dtype=np.float32)\n",
    "    result = func(x, h)\n",
    "    np.testing.assert_equal(result, [0, 1, 4, 7, 10])\n",
    "    \n",
    "    # Test a bit longer filter.\n",
    "    x = np.arange(10).astype(np.float32)\n",
    "    h = np.arange(5).astype(np.float32)\n",
    "    result = func(x, h)\n",
    "    np.testing.assert_equal(result, np.convolve(x, h, mode='same'))\n",
    "        \n",
    "    # Test if it gives the \"same\" results as nump.convolve. \n",
    "    rng = np.random.default_rng(29062021)\n",
    "    for i in range(100):\n",
    "        intervals = rng.integers(low=1, high=30, size=2)\n",
    "        h_len, x_len = sorted(intervals)\n",
    "        x = rng.random(x_len).astype(np.float32)\n",
    "        h = rng.random(h_len).astype(np.float32)\n",
    "        result = func(x, h)\n",
    "        np.testing.assert_almost_equal(result, np.convolve(x, h, mode='same'), decimal=5)\n",
    "    \n",
    "    print(\"All tests passed.\")\n",
    "    \n",
    "    \n",
    "def benchmark_convolve(func, n=20, x_size=10000, h_size=256):\n",
    "    import time\n",
    "\n",
    "    times = []\n",
    "    for i in range(n):\n",
    "        x = np.random.rand(x_size).astype(np.float32)\n",
    "        h = np.random.rand(h_size).astype(np.float32)\n",
    "        start = time.time()\n",
    "        result = func(x, h)\n",
    "        end = time.time()\n",
    "        times.append(end-start)\n",
    "    print(\"Benchmark result: \")\n",
    "    print(f\"Average processing time: \" \n",
    "        + f\"{np.mean(times):.4f} \"\n",
    "        + f\"seconds (+/- {np.std(times).item():.4f}), \"\n",
    "        + f\"median: {np.median(times):.4f}\")\n",
    "    \n",
    "test_convolve(convolve_cpu)\n",
    "benchmark_convolve(convolve_cpu, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-croatia",
   "metadata": {},
   "source": [
    "### Naive CUDA kernel implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "realistic-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def convolve_gpu_kernel(y, x, h):\n",
    "    i = cuda.grid(1)\n",
    "    M = len(x)\n",
    "    N = len(h)\n",
    "    offset = int32(math.ceil(N/2)-1)\n",
    "    \n",
    "    if i >= len(y):\n",
    "        return\n",
    "    \n",
    "    value = float32(0.0)\n",
    "    \n",
    "    for j in range(N):\n",
    "        k = i + offset - j\n",
    "        if k >= 0 and k < M:\n",
    "            value += x[k]*h[j]\n",
    "    \n",
    "    y[i] = value\n",
    "    \n",
    "def convolve_gpu(y, x, h):\n",
    "    if y is None:\n",
    "        y = cuda.device_array(x.shape, dtype=x.dtype)\n",
    "    block_size = (256, )\n",
    "    grid_size = (math.ceil(len(y)/block_size[0]), )\n",
    "    convolve_gpu_kernel[grid_size, block_size](y, x, h)\n",
    "    return y.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removable-renaissance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed.\n",
      "Benchmark result: \n",
      "Average processing time: 0.0010 seconds (+/- 0.0000), median: 0.0010\n"
     ]
    }
   ],
   "source": [
    "test_convolve(lambda x, h: convolve_gpu(None, x, h))\n",
    "benchmark_convolve(lambda x, h: convolve_gpu(None, x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-product",
   "metadata": {},
   "source": [
    "### Profiling the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dated-picking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 2_1_convolve_global_memory.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 2_1_convolve_global_memory.py\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda, float32, int32\n",
    "from tests import benchmark_convolve\n",
    "\n",
    "@cuda.jit\n",
    "def convolve_gpu_kernel(y, x, h):\n",
    "    i = cuda.grid(1)\n",
    "    M = len(x)\n",
    "    N = len(h)\n",
    "    offset = int32(math.ceil(N/2)-1)\n",
    "    \n",
    "    if i >= len(y):\n",
    "        return\n",
    "    \n",
    "    value = float32(0.0)\n",
    "    \n",
    "    for j in range(N):\n",
    "        k = i + offset - j\n",
    "        if k >= 0 and k < M:\n",
    "            value += x[k]*h[j]\n",
    "    \n",
    "    y[i] = value\n",
    "    \n",
    "def convolve_gpu(y, x, h):\n",
    "    if y is None:\n",
    "        y = cuda.device_array(x.shape, dtype=x.dtype)\n",
    "    block_size = (256, )\n",
    "    grid_size = (math.ceil(len(y)/block_size[0]), )\n",
    "    convolve_gpu_kernel[grid_size, block_size](y, x, h)\n",
    "    return y.copy_to_host()\n",
    "\n",
    "benchmark_convolve(lambda x, h: convolve_gpu(None, x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rising-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==20258== NVPROF is profiling process 20258, command: python 2_1_convolve_global_memory.py\n",
      "Benchmark result: \n",
      "Average processing time: 0.0293 seconds (+/- 0.0539), median: 0.0229\n",
      "==20258== Profiling application: python 2_1_convolve_global_memory.py\n",
      "==20258== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   80.85%  1.78268s       100  17.827ms  17.257ms  28.191ms  cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=1, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\n",
      "                   12.27%  270.61ms       300  902.03us  1.1200us  2.8563ms  [CUDA memcpy DtoH]\n",
      "                    6.88%  151.75ms       200  758.76us     896ns  2.2119ms  [CUDA memcpy HtoD]\n",
      "      API calls:   86.48%  2.08104s       300  6.9368ms  13.580us  29.745ms  cuMemcpyDtoH\n",
      "                    5.73%  138.00ms       200  690.01us  7.8420us  2.0586ms  cuMemcpyHtoD\n",
      "                    4.95%  119.21ms         1  119.21ms  119.21ms  119.21ms  cuDevicePrimaryCtxRetain\n",
      "                    1.51%  36.418ms       300  121.39us  3.7860us  2.0227ms  cuMemAlloc\n",
      "                    1.20%  28.994ms       297  97.622us  2.3700us  1.4176ms  cuMemFree\n",
      "                    0.05%  1.3169ms       100  13.169us  9.1980us  65.358us  cuLaunchKernel\n",
      "                    0.02%  405.93us      1003     404ns     205ns  2.8460us  cuCtxGetCurrent\n",
      "                    0.01%  256.78us      1001     256ns     129ns  2.7590us  cuCtxGetDevice\n",
      "                    0.01%  170.58us         1  170.58us  170.58us  170.58us  cuModuleLoadDataEx\n",
      "                    0.01%  164.34us       101  1.6270us     162ns  74.526us  cuDeviceGetAttribute\n",
      "                    0.00%  98.445us         1  98.445us  98.445us  98.445us  cuLinkComplete\n",
      "                    0.00%  97.974us         1  97.974us  97.974us  97.974us  cuLinkAddData\n",
      "                    0.00%  87.569us         2  43.784us  42.211us  45.358us  cuDeviceGetName\n",
      "                    0.00%  74.787us         1  74.787us  74.787us  74.787us  cuDeviceTotalMem\n",
      "                    0.00%  45.148us         1  45.148us  45.148us  45.148us  cuLinkCreate\n",
      "                    0.00%  21.070us         1  21.070us  21.070us  21.070us  cuMemGetInfo\n",
      "                    0.00%  8.6100us         1  8.6100us  8.6100us  8.6100us  cuDeviceGetPCIBusId\n",
      "                    0.00%  3.8880us         4     972ns     297ns  2.5990us  cuDeviceGetCount\n",
      "                    0.00%  2.2410us         3     747ns     403ns  1.0240us  cuDeviceGet\n",
      "                    0.00%  1.9150us         1  1.9150us  1.9150us  1.9150us  cuInit\n",
      "                    0.00%  1.6950us         5     339ns     165ns     772ns  cuFuncGetAttribute\n",
      "                    0.00%  1.4520us         1  1.4520us  1.4520us  1.4520us  cuModuleGetFunction\n",
      "                    0.00%  1.3820us         1  1.3820us  1.3820us  1.3820us  cuLinkDestroy\n",
      "                    0.00%  1.2330us         1  1.2330us  1.2330us  1.2330us  cuCtxPushCurrent\n",
      "                    0.00%  1.0580us         1  1.0580us  1.0580us  1.0580us  cuDeviceComputeCapability\n",
      "                    0.00%  1.0260us         1  1.0260us  1.0260us  1.0260us  cuDriverGetVersion\n",
      "                    0.00%     549ns         1     549ns     549ns     549ns  cudaRuntimeGetVersion\n",
      "                    0.00%     430ns         1     430ns     430ns     430ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "! nvprof python 2_1_convolve_global_memory.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
