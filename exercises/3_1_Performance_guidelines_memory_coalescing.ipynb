{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outer-promise",
   "metadata": {},
   "source": [
    "# 3.1. Performance guidelines: memory coalescing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-point",
   "metadata": {},
   "source": [
    "Let's move back for a while to the basic CUDA kernel convolution implemenation, with no shared and constant memory (for the sake of simplicity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-activation",
   "metadata": {},
   "source": [
    "Let's extend the example to be possible to do 1-D convolution on a 2-D Array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sacred-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda, float32, int32\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pleasant-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def convolve_gpu_kernel(y, x, h):\n",
    "    i = cuda.blockIdx.x*cuda.blockDim.x + cuda.threadIdx.x\n",
    "    j = cuda.blockIdx.y*cuda.blockDim.y + cuda.threadIdx.y\n",
    "\n",
    "    N = len(h)\n",
    "    offset = int32(math.ceil(N/2)-1)\n",
    "    \n",
    "    HEIGHT = x.shape[0]\n",
    "    WIDTH = x.shape[1]\n",
    "    \n",
    "    if i >= WIDTH or j >= HEIGHT:\n",
    "        return\n",
    "    \n",
    "    value = float32(0.0)\n",
    "    for k in range(N):\n",
    "        l = i + offset - k\n",
    "        if l >= 0 and l < WIDTH:\n",
    "            value += x[j, l]*h[k]\n",
    "            \n",
    "    y[j, i] = value\n",
    "    \n",
    "    \n",
    "def convolve_gpu(y, x, h):\n",
    "    block_size = (32, 32)\n",
    "    height, width = x.shape\n",
    "    # The left most index is the most quickly changing one.\n",
    "    grid_size = (math.ceil(width/block_size[1]), math.ceil(height/block_size[0]))\n",
    "    convolve_gpu_kernel[grid_size, block_size](y, x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-investigation",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "directed-stanley",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n",
      "[[  0.   1.   4.   7.  10.]\n",
      " [ 10.  40.  70. 100. 130.]\n",
      " [ -1.  -4.  -7. -10. -13.]]\n"
     ]
    }
   ],
   "source": [
    "x_host = np.array(\n",
    "    [[ 0,  1,  2,  3,  4],\n",
    "     [10, 20, 30, 40, 50],\n",
    "     [-1, -2, -3, -4, -5]])\n",
    "x_host = x_host.astype(np.float32)\n",
    "\n",
    "h_host = np.array([0, 1, 2])\n",
    "h_host = h_host.astype(np.float32)\n",
    "\n",
    "x_gpu = cuda.to_device(x_host)\n",
    "h_gpu = cuda.to_device(h_host)\n",
    "y_gpu = cuda.device_array(x_gpu.shape, dtype=x_gpu.dtype)\n",
    "print(y_gpu.shape)\n",
    "convolve_gpu(y_gpu, x_gpu, h_gpu)\n",
    "print(y_gpu.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-packaging",
   "metadata": {},
   "source": [
    "Depending on the axis along which we would like to perform the convolution, we will get two different performance results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-light",
   "metadata": {},
   "source": [
    "### I. Convolve along the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "qualified-sending",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 3_1_memory_coalescing_axis_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 3_1_memory_coalescing_axis_1.py\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda, float32, int32\n",
    "import cupy as cp\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def convolve_gpu_kernel(y, x, h):\n",
    "    i = cuda.blockIdx.x*cuda.blockDim.x + cuda.threadIdx.x\n",
    "    j = cuda.blockIdx.y*cuda.blockDim.y + cuda.threadIdx.y\n",
    "\n",
    "    N = len(h)\n",
    "    offset = int32(math.ceil(N/2)-1)\n",
    "    \n",
    "    HEIGHT = x.shape[0]\n",
    "    WIDTH = x.shape[1]\n",
    "    \n",
    "    if i >= HEIGHT or j >= WIDTH:\n",
    "        return\n",
    "    \n",
    "    value = float32(0.0)\n",
    "    for k in range(N):\n",
    "        l = i + offset - k\n",
    "        if l >= 0 and l < HEIGHT:\n",
    "            value += x[l, j]*h[k]\n",
    "            \n",
    "    y[i, j] = value\n",
    "    \n",
    "    \n",
    "def convolve_gpu(y, x, h):\n",
    "    block_size = (32, 32)\n",
    "    height, width = x.shape\n",
    "    # The left most index is the most quickly changing one.\n",
    "    grid_size = (math.ceil(width/block_size[1]), math.ceil(height/block_size[0]))\n",
    "    convolve_gpu_kernel[grid_size, block_size](y, x, h)\n",
    "    \n",
    "    \n",
    "for i in range(10):\n",
    "    x_host = np.random.rand(256, 256).astype(np.float32)\n",
    "    h_host = np.random.rand(32).astype(np.float32)\n",
    "    x_gpu = cuda.to_device(x_host)\n",
    "    h_gpu = cuda.to_device(h_host)\n",
    "    y_gpu = cuda.device_array(x_gpu.shape, dtype=x_gpu.dtype)\n",
    "    convolve_gpu(y_gpu, x_gpu, h_gpu)\n",
    "    y_host = y_gpu.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "optical-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==8889== NVPROF is profiling process 8889, command: python 3_1_memory_coalescing_axis_1.py\n",
      "==8889== Profiling application: python 3_1_memory_coalescing_axis_1.py\n",
      "==8889== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   69.06%  3.7648ms        10  376.48us  371.98us  378.80us  cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\n",
      "                   16.17%  881.24us        20  44.062us     864ns  91.644us  [CUDA memcpy HtoD]\n",
      "                   14.77%  805.21us        10  80.521us  79.292us  89.597us  [CUDA memcpy DtoH]\n",
      "No API activities were profiled.\n"
     ]
    }
   ],
   "source": [
    "! nvprof --trace gpu python 3_1_memory_coalescing_axis_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-dietary",
   "metadata": {},
   "source": [
    "### II. Convolve along the second axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adequate-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 3_1_memory_coalescing_axis_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 3_1_memory_coalescing_axis_2.py\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda, float32, int32\n",
    "import cupy as cp\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def convolve_gpu_kernel(y, x, h):\n",
    "    i = cuda.blockIdx.x*cuda.blockDim.x + cuda.threadIdx.x\n",
    "    j = cuda.blockIdx.y*cuda.blockDim.y + cuda.threadIdx.y\n",
    "\n",
    "    N = len(h)\n",
    "    offset = int32(math.ceil(N/2)-1)\n",
    "    \n",
    "    HEIGHT = x.shape[0]\n",
    "    WIDTH = x.shape[1]\n",
    "    \n",
    "    if i >= WIDTH or j >= HEIGHT:\n",
    "        return\n",
    "    \n",
    "    value = float32(0.0)\n",
    "    for k in range(N):\n",
    "        l = i + offset - k\n",
    "        if l >= 0 and l < WIDTH:\n",
    "            value += x[j, l]*h[k]\n",
    "            \n",
    "    y[j, i] = value\n",
    "    \n",
    "    \n",
    "def convolve_gpu(y, x, h):\n",
    "    block_size = (32, 32)\n",
    "    height, width = x.shape\n",
    "    # The left most index is the most quickly changing one.\n",
    "    grid_size = (math.ceil(width/block_size[1]), math.ceil(height/block_size[0]))\n",
    "    convolve_gpu_kernel[grid_size, block_size](y, x, h)\n",
    "    \n",
    "for i in range(10):\n",
    "    x_host = np.random.rand(256, 256).astype(np.float32)\n",
    "    h_host = np.random.rand(32).astype(np.float32)\n",
    "    x_gpu = cuda.to_device(x_host)\n",
    "    h_gpu = cuda.to_device(h_host)\n",
    "    y_gpu = cuda.device_array(x_gpu.shape, dtype=x_gpu.dtype)\n",
    "    convolve_gpu(y_gpu, x_gpu, h_gpu)\n",
    "    y_host = y_gpu.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "rising-tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==8917== NVPROF is profiling process 8917, command: python 3_1_memory_coalescing_axis_2.py\n",
      "==8917== Profiling application: python 3_1_memory_coalescing_axis_2.py\n",
      "==8917== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   55.58%  2.2042ms        10  220.42us  218.23us  222.68us  cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\n",
      "                   22.29%  883.87us        20  44.193us     863ns  97.532us  [CUDA memcpy HtoD]\n",
      "                   22.13%  877.69us        10  87.769us  79.261us  158.62us  [CUDA memcpy DtoH]\n",
      "No API activities were profiled.\n"
     ]
    }
   ],
   "source": [
    "! nvprof --trace gpu python 3_1_memory_coalescing_axis_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "civilian-constant",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==8946== NVPROF is profiling process 8946, command: python 3_1_memory_coalescing_axis_1.py\n",
      "==8946== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t2 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t1 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8946== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8946== Profiling application: python 3_1_memory_coalescing_axis_1.py\n",
      "==8946== Profiling result:\n",
      "==8946== Metric result:\n",
      "Invocations                               Metric Name                        Metric Description         Min         Max         Avg\n",
      "Device \"GeForce MX250 (0)\"\n",
      "    Kernel: cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\n",
      "         10                            gld_efficiency             Global Memory Load Efficiency      12.50%      12.50%      12.50%\n",
      "         10                            gst_efficiency            Global Memory Store Efficiency      12.50%      12.50%      12.50%\n"
     ]
    }
   ],
   "source": [
    "! nvprof --profile-api-trace none --metrics gld_efficiency,gst_efficiency python 3_1_memory_coalescing_axis_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "yellow-field",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==8976== NVPROF is profiling process 8976, command: python 3_1_memory_coalescing_axis_2.py\n",
      "==8976== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t4 internal events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Replaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (1 of 4)... \n",
      "\t1 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (2 of 4)... \n",
      "\t2 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (3 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[K\n",
      "\u001b[2A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (4 of 4)... \n",
      "\t4 internal events\n",
      "==8976== \u001b[1A\n",
      "\u001b[K\u001b[2A\u001b[K\n",
      "\u001b[1A\u001b[KReplaying kernel \"cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\" (done)\n",
      "==8976== Profiling application: python 3_1_memory_coalescing_axis_2.py\n",
      "==8976== Profiling result:\n",
      "==8976== Metric result:\n",
      "Invocations                               Metric Name                        Metric Description         Min         Max         Avg\n",
      "Device \"GeForce MX250 (0)\"\n",
      "    Kernel: cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=2, C, mutable, aligned>, Array<float, int=2, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\n",
      "         10                            gld_efficiency             Global Memory Load Efficiency      70.23%      70.23%      70.23%\n",
      "         10                            gst_efficiency            Global Memory Store Efficiency     100.00%     100.00%     100.00%\n"
     ]
    }
   ],
   "source": [
    "! nvprof --profile-api-trace none --metrics gld_efficiency,gst_efficiency python 3_1_memory_coalescing_axis_2.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
