{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda, float32, int32\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-bidding",
   "metadata": {},
   "source": [
    "## How much global memory we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sound-eugene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: b'GeForce MX250'\n",
      "Shared memory per thread block: 2099904512 [bytes]\n"
     ]
    }
   ],
   "source": [
    "device_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "\n",
    "print(f\"Device name: {device_props['name']}\")\n",
    "print(f\"Shared memory per thread block: {device_props['totalGlobalMem']} [bytes]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-nightlife",
   "metadata": {},
   "source": [
    "***\n",
    "# FIR filter\n",
    "***\n",
    "<font size=\"4\">\n",
    "The finite impulse response (FIR) filter is given by equation \\eqref{fir}\n",
    "\n",
    "\\begin{equation}\n",
    "    y_i = \\sum_{j=0}^{N-1} h_j x_{i+\\left\\lceil \\frac{N}{2} \\right\\rceil+1-j} \n",
    "    \\label{fir} \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "where *x* is an input signal, *h* is the impulse response of the filter and *y* is an output signal.\n",
    "Filtration is realised by convolving the signal with impulse response of the filter.\n",
    "\n",
    "$x_i$ is equal 0 for $i < 0$\n",
    "    \n",
    "***    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-brain",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "developing-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  7, 10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.convolve([0, 1, 2, 3, 4], [0, 1, 2], mode='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-winning",
   "metadata": {},
   "source": [
    "Examples:\n",
    "    \n",
    "```\n",
    "\n",
    "x = [0, 1, 2, 3, 4]\n",
    "h = [0, 1, 2]\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    " x = [0, 1, 2, 3, 4]      y = \n",
    "     [1, 0]               [0 ]\n",
    "     [2, 1, 0]            [1 ]\n",
    "        [2, 1, 0]         [4 ]\n",
    "           [2, 1, 0]      [7 ]\n",
    "              [2, 1]      [10]\n",
    "```\n",
    "\n",
    "```\n",
    "y[0] = h[0]*x[1]+h[1]*x[0]           = 0\n",
    "y[1] = h[0]*x[2]+h[1]*x[1]*h[2]*x[0] = 1\n",
    "y[2] = h[0]*x[3]+h[1]*x[2]*h[2]*x[1] = 4\n",
    "y[3] = h[0]*x[4]+h[1]*x[3]+h[2]*x[2] = 7\n",
    "y[4] = h[1]*x[4]+h[2]*x[3] =           10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-homework",
   "metadata": {},
   "source": [
    "### CPU implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "temporal-mexican",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  7, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convolve_cpu(x, h):\n",
    "    x = np.asarray(x)\n",
    "    h = np.asarray(h)\n",
    "    M = len(x)\n",
    "    N = len(h)\n",
    "    y = np.zeros(M, dtype=x.dtype)\n",
    "    offset = math.ceil(N/2)-1\n",
    "        \n",
    "    for i in range(M):\n",
    "        # This loop can be parallelized.\n",
    "        value = 0.0\n",
    "        for j in range(N):\n",
    "            k = i + offset - j    \n",
    "            if k >= 0 and k < M:\n",
    "                value += x[k]*h[j]\n",
    "        y[i] = value\n",
    "        \n",
    "    return y\n",
    "\n",
    "\n",
    "convolve_cpu([0, 1, 2, 3, 4], [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brave-conducting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed.\n",
      "Benchmark result: \n",
      "Average processing time: 1.2196 seconds (+/- 0.0063), median: 1.2196\n"
     ]
    }
   ],
   "source": [
    "def test_convolve(func):\n",
    "    # Test simple case\n",
    "    x = np.array([0, 1, 2, 3, 4], dtype=np.float32)\n",
    "    h = np.array([0, 1, 2], dtype=np.float32)\n",
    "    result = func(x, h)\n",
    "    np.testing.assert_equal(result, [0, 1, 4, 7, 10])\n",
    "    \n",
    "    # Test a bit longer filter.\n",
    "    x = np.arange(10).astype(np.float32)\n",
    "    h = np.arange(5).astype(np.float32)\n",
    "    result = func(x, h)\n",
    "    np.testing.assert_equal(result, np.convolve(x, h, mode='same'))\n",
    "        \n",
    "    # Test if it gives the \"same\" results as nump.convolve. \n",
    "    rng = np.random.default_rng(29062021)\n",
    "    for i in range(100):\n",
    "        intervals = rng.integers(low=1, high=30, size=2)\n",
    "        h_len, x_len = sorted(intervals)\n",
    "        x = rng.random(x_len).astype(np.float32)\n",
    "        h = rng.random(h_len).astype(np.float32)\n",
    "        result = func(x, h)\n",
    "        np.testing.assert_almost_equal(result, np.convolve(x, h, mode='same'), decimal=5)\n",
    "    \n",
    "    print(\"All tests passed.\")\n",
    "    \n",
    "    \n",
    "def benchmark_convolve(func, n=20, x_size=10000, h_size=256):\n",
    "    import time\n",
    "\n",
    "    times = []\n",
    "    for i in range(n):\n",
    "        x = np.random.rand(x_size).astype(np.float32)\n",
    "        h = np.random.rand(h_size).astype(np.float32)\n",
    "        start = time.time()\n",
    "        result = func(x, h)\n",
    "        end = time.time()\n",
    "        times.append(end-start)\n",
    "    print(\"Benchmark result: \")\n",
    "    print(f\"Average processing time: \" \n",
    "        + f\"{np.mean(times):.4f} \"\n",
    "        + f\"seconds (+/- {np.std(times).item():.4f}), \"\n",
    "        + f\"median: {np.median(times):.4f}\")\n",
    "    \n",
    "test_convolve(convolve_cpu)\n",
    "benchmark_convolve(convolve_cpu, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-croatia",
   "metadata": {},
   "source": [
    "### Naive CUDA kernel implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "realistic-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def convolve_gpu_kernel(y, x, h):\n",
    "    i = cuda.grid(1)\n",
    "    M = len(x)\n",
    "    N = len(h)\n",
    "    offset = int32(math.ceil(N/2)-1)\n",
    "    \n",
    "    if i >= len(y):\n",
    "        return\n",
    "    \n",
    "    value = float32(0.0)\n",
    "    \n",
    "    for j in range(N):\n",
    "        k = i + offset - j\n",
    "        if k >= 0 and k < M:\n",
    "            value += x[k]*h[j]\n",
    "    \n",
    "    y[i] = value\n",
    "    \n",
    "def convolve_gpu(y, x, h):\n",
    "    if y is None:\n",
    "        y = cuda.device_array(x.shape, dtype=x.dtype)\n",
    "    block_size = (256, )\n",
    "    grid_size = (math.ceil(len(y)/block_size[0]), )\n",
    "    convolve_gpu_kernel[grid_size, block_size](y, x, h)\n",
    "    return y.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removable-renaissance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed.\n",
      "Benchmark result: \n",
      "Average processing time: 0.0010 seconds (+/- 0.0000), median: 0.0010\n"
     ]
    }
   ],
   "source": [
    "test_convolve(lambda x, h: convolve_gpu(None, x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-product",
   "metadata": {},
   "source": [
    "## Profiling the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dated-picking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 2_1_convolve_global_memory.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 2_1_convolve_global_memory.py\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda, float32, int32\n",
    "from tests import benchmark_convolve\n",
    "\n",
    "@cuda.jit\n",
    "def convolve_gpu_kernel(y, x, h):\n",
    "    i = cuda.grid(1)\n",
    "    M = len(x)\n",
    "    N = len(h)\n",
    "    offset = int32(math.ceil(N/2)-1)\n",
    "    \n",
    "    if i >= len(y):\n",
    "        return\n",
    "    \n",
    "    value = float32(0.0)\n",
    "    \n",
    "    for j in range(N):\n",
    "        k = i + offset - j\n",
    "        if k >= 0 and k < M:\n",
    "            value += x[k]*h[j]\n",
    "    \n",
    "    y[i] = value\n",
    "    \n",
    "def convolve_gpu(y, x, h):\n",
    "    if y is None:\n",
    "        y = cuda.device_array(x.shape, dtype=x.dtype)\n",
    "    block_size = (256, )\n",
    "    grid_size = (math.ceil(len(y)/block_size[0]), )\n",
    "    convolve_gpu_kernel[grid_size, block_size](y, x, h)\n",
    "    return y.copy_to_host()\n",
    "\n",
    "benchmark_convolve(lambda x, h: convolve_gpu(None, x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "worse-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==19938== NVPROF is profiling process 19938, command: python 2_1_convolve_global_memory.py\n",
      "Benchmark result: \n",
      "Average processing time: 0.0284 seconds (+/- 0.0524), median: 0.0229\n",
      "==19938== Profiling application: python 2_1_convolve_global_memory.py\n",
      "==19938== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   80.75%  1.73488s       100  17.349ms  17.181ms  21.013ms  cudapy::__main__::convolve_gpu_kernel$241(Array<float, int=1, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>, Array<float, int=1, C, mutable, aligned>)\n",
      "                   12.24%  262.93ms       300  876.43us  1.1200us  2.6095ms  [CUDA memcpy DtoH]\n",
      "                    7.01%  150.55ms       200  752.77us     896ns  1.6102ms  [CUDA memcpy HtoD]\n",
      "      API calls:   86.70%  2.02298s       300  6.7433ms  13.343us  22.405ms  cuMemcpyDtoH\n",
      "                    5.85%  136.41ms       200  682.06us  7.6980us  1.1795ms  cuMemcpyHtoD\n",
      "                    4.85%  113.11ms         1  113.11ms  113.11ms  113.11ms  cuDevicePrimaryCtxRetain\n",
      "                    1.32%  30.747ms       300  102.49us  3.7690us  1.9611ms  cuMemAlloc\n",
      "                    1.17%  27.307ms       297  91.943us  2.1810us  146.22us  cuMemFree\n",
      "                    0.06%  1.4070ms       100  14.069us  9.7420us  30.433us  cuLaunchKernel\n",
      "                    0.02%  362.54us      1003     361ns     190ns  4.5530us  cuCtxGetCurrent\n",
      "                    0.01%  251.33us      1001     251ns     141ns  1.2550us  cuCtxGetDevice\n",
      "                    0.01%  167.60us       101  1.6590us     154ns  65.656us  cuDeviceGetAttribute\n",
      "                    0.01%  133.26us         1  133.26us  133.26us  133.26us  cuModuleLoadDataEx\n",
      "                    0.00%  102.94us         1  102.94us  102.94us  102.94us  cuLinkAddData\n",
      "                    0.00%  93.523us         1  93.523us  93.523us  93.523us  cuLinkComplete\n",
      "                    0.00%  67.270us         2  33.635us  25.972us  41.298us  cuDeviceGetName\n",
      "                    0.00%  67.207us         1  67.207us  67.207us  67.207us  cuDeviceTotalMem\n",
      "                    0.00%  45.179us         1  45.179us  45.179us  45.179us  cuLinkCreate\n",
      "                    0.00%  20.749us         1  20.749us  20.749us  20.749us  cuMemGetInfo\n",
      "                    0.00%  8.4440us         1  8.4440us  8.4440us  8.4440us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.4130us         1  2.4130us  2.4130us  2.4130us  cudaRuntimeGetVersion\n",
      "                    0.00%  2.2780us         4     569ns     205ns  1.3020us  cuDeviceGetCount\n",
      "                    0.00%  2.0850us         3     695ns     382ns  1.0510us  cuDeviceGet\n",
      "                    0.00%  2.0280us         1  2.0280us  2.0280us  2.0280us  cuInit\n",
      "                    0.00%  1.6810us         5     336ns     177ns     735ns  cuFuncGetAttribute\n",
      "                    0.00%  1.3040us         1  1.3040us  1.3040us  1.3040us  cuLinkDestroy\n",
      "                    0.00%  1.2620us         1  1.2620us  1.2620us  1.2620us  cuModuleGetFunction\n",
      "                    0.00%  1.1640us         1  1.1640us  1.1640us  1.1640us  cuCtxPushCurrent\n",
      "                    0.00%  1.0720us         1  1.0720us  1.0720us  1.0720us  cuDriverGetVersion\n",
      "                    0.00%     589ns         1     589ns     589ns     589ns  cuDeviceComputeCapability\n",
      "                    0.00%     368ns         1     368ns     368ns     368ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "! nvprof python 2_1_convolve_global_memory.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
